package sda

import (
	"bytes"
	"context"
	"crypto/tls"
	"crypto/x509"
	"errors"
	"fmt"
	"io"
	"net/http"
	"os"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/neicnordic/crypt4gh/streaming"
	"github.com/neicnordic/sda-download/api/middleware"
	"github.com/neicnordic/sda-download/internal/config"
	"github.com/neicnordic/sda-download/internal/database"
	"github.com/neicnordic/sda-download/internal/reencrypt"
	"github.com/neicnordic/sda-download/internal/storage"
	log "github.com/sirupsen/logrus"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
	"google.golang.org/grpc/credentials/insecure"
)

var Backend storage.Backend

func sanitizeString(str string) string {
	var pattern = regexp.MustCompile(`(https?://[^\s/$.?#].[^\s]+|[A-Za-z0-9-_:.]+)`)

	return pattern.ReplaceAllString(str, "[identifier]: $1")
}

func reencryptHeader(oldHeader []byte, reencKey string, dataeditlist ...uint64) ([]byte, error) {
	var opts []grpc.DialOption
	switch {
	case config.Config.Reencrypt.ClientKey != "" && config.Config.Reencrypt.ClientCert != "":
		rootCAs, err := x509.SystemCertPool()
		if err != nil {
			log.Errorf("failed to read system CAs: %v, using an empty pool as base", err)
			rootCAs = x509.NewCertPool()
		}
		if config.Config.Reencrypt.CACert != "" {
			cacertByte, err := os.ReadFile(config.Config.Reencrypt.CACert)
			if err != nil {
				log.Errorf("Failed to read CA certificate file, reason: %s", err)

				return nil, err
			}
			ok := rootCAs.AppendCertsFromPEM(cacertByte)
			if !ok {
				log.Errorf("Failed to append CA certificate to rootCAs")

				return nil, errors.New("failed to append CA certificate to cert pool")
			}
		}

		certs, err := tls.LoadX509KeyPair(config.Config.Reencrypt.ClientCert, config.Config.Reencrypt.ClientKey)
		if err != nil {
			log.Errorf("Failed to load client key pair for reencrypt, reason: %s", err)

			return nil, err
		}
		clientCreds := credentials.NewTLS(
			&tls.Config{
				Certificates: []tls.Certificate{certs},
				MinVersion:   tls.VersionTLS13,
				RootCAs:      rootCAs,
			},
		)

		opts = append(opts, grpc.WithTransportCredentials(clientCreds))
	default:
		opts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials()))
	}

	address := fmt.Sprintf("%s:%d", config.Config.Reencrypt.Host, config.Config.Reencrypt.Port)
	log.Debugf("Address of the reencrypt service: %s", address)

	conn, err := grpc.NewClient(address, opts...)
	if err != nil {
		log.Errorf("Failed to connect to the reencrypt service, reason: %s", err)

		return nil, err
	}
	defer conn.Close()

	timeoutDuration := time.Duration(config.Config.Reencrypt.Timeout) * time.Second
	ctx, cancel := context.WithTimeout(context.Background(), timeoutDuration)
	defer cancel()

	c := reencrypt.NewReencryptClient(conn)
	log.Debugf("Client created, c = %v", c)

	request := reencrypt.ReencryptRequest{Oldheader: oldHeader, Publickey: reencKey}

	if len(dataeditlist) > 0 {
		request.Dataeditlist = dataeditlist
	}

	res, err := c.ReencryptHeader(ctx, &request)
	if err != nil {
		log.Errorf("Failed response from the reencrypt service, reason: %s", err)

		return nil, err
	}
	log.Debugf("Response from the reencrypt service: %v", res)

	return res.Header, nil
}

// Datasets serves a list of permitted datasets
func Datasets(c *gin.Context) {
	log.Debugf("request permitted datasets")

	// Retrieve dataset list from request context
	// generated by the authentication middleware
	cache := middleware.GetCacheFromContext(c)

	// Return response
	c.JSON(http.StatusOK, cache.Datasets)
}

// find looks for a dataset name in a list of datasets
func find(datasetID string, datasets []string) bool {
	found := false
	for _, dataset := range datasets {
		if datasetID == dataset {
			found = true

			break
		}
	}

	return found
}

// getFiles returns files belonging to a dataset
var getFiles = func(datasetID string, ctx *gin.Context) ([]*database.FileInfo, int, error) {

	// Retrieve dataset list from request context
	// generated by the authentication middleware
	cache := middleware.GetCacheFromContext(ctx)

	log.Debugf("request to process files for dataset %s", sanitizeString(datasetID))

	if find(datasetID, cache.Datasets) {
		// Get file metadata
		files, err := database.GetFiles(datasetID)
		if err != nil {
			// something went wrong with querying or parsing rows
			log.Errorf("database query failed for dataset %s, reason %s", sanitizeString(datasetID), err)

			return nil, 500, errors.New("database error")
		}

		return files, 200, nil
	}

	return nil, 404, errors.New("dataset not found")
}

// Files serves a list of files belonging to a dataset
func Files(c *gin.Context) {

	// get dataset parameter
	dataset := c.Param("dataset")

	if !strings.HasSuffix(dataset, "/files") {
		c.String(http.StatusNotFound, "API path not found, maybe /files is missing")

		return
	}

	// remove / prefix and /files suffix
	dataset = strings.TrimPrefix(dataset, "/")
	dataset = strings.TrimSuffix(dataset, "/files")

	// Get optional dataset scheme
	// A scheme can be delivered separately in a query parameter
	// as schemes may sometimes be problematic when they travel
	// in the path. A client can conveniently split the scheme with "://"
	// which results in 1 item if there is no scheme (e.g. EGAD) or 2 items
	// if there was a scheme (e.g. DOI)
	scheme := c.Query("scheme")
	schemeLogs := strings.ReplaceAll(scheme, "\n", "")
	schemeLogs = strings.ReplaceAll(schemeLogs, "\r", "")

	datasetLogs := strings.ReplaceAll(dataset, "\n", "")
	datasetLogs = strings.ReplaceAll(datasetLogs, "\r", "")
	if scheme != "" {
		log.Debugf("adding scheme=%s to dataset=%s", schemeLogs, datasetLogs)
		dataset = fmt.Sprintf("%s://%s", scheme, dataset)
		log.Debugf("new dataset=%s", datasetLogs)
	}

	// Get dataset files
	files, code, err := getFiles(dataset, c)
	if err != nil {
		c.String(code, err.Error())

		return
	}

	// Return response
	c.JSON(http.StatusOK, files)
}

// Download serves file contents as bytes
func Download(c *gin.Context) {

	// Get file ID from path
	fileID := c.Param("fileid")

	// Check user has permissions for this file (as part of a dataset)
	dataset, err := database.CheckFilePermission(fileID)
	if err != nil {
		c.String(http.StatusNotFound, "file not found")

		return
	}

	// Get datasets from request context, parsed previously by token middleware
	cache := middleware.GetCacheFromContext(c)

	// Verify user has permission to datafile
	permission := false
	for d := range cache.Datasets {
		if cache.Datasets[d] == dataset {
			permission = true

			break
		}
	}
	if !permission {
		log.Debugf("user requested to view file, but does not have permissions for dataset %s", dataset)
		c.String(http.StatusUnauthorized, "unauthorised")

		return
	}

	// Get file header
	fileDetails, err := database.GetFile(fileID)
	if err != nil {
		c.String(http.StatusInternalServerError, "database error")

		return
	}

	coords, err := getCoordinates(c, fileDetails)
	if err != nil {
		log.Errorf("Coordinate parse error: %v", err)
		c.String(http.StatusInternalServerError, "failed to parse range/coordinates")

		return
	}

	if len(coords) > 1 {
		log.Warnf("Multiple ranges were requested but this is currently unsupported: %v", coords)
		// Should we use a 416 here instead? Or determine what should be returned and fix it, might
		// have use cases for e.g. Cytomine
		c.String(http.StatusInternalServerError, "multiple ranges is not yet supported")

		return
	}

	if c.Param("type") != "encrypted" {
		// set the content-length for unencrypted files
		if len(coords) == 0 {
			// No coordinates specified, so we're sending the whole file
			c.Header("Content-Length", fmt.Sprint(fileDetails.DecryptedSize))
		} else {
			// Calculate how much we should read (if given)
			c.Header("Content-Length", fmt.Sprint(coords[0].end-coords[0].start))
		}
	}

	// Get archive file handle
	var file io.Reader

	if len(coords) == 0 {
		file, err = Backend.NewFileReader(fileDetails.ArchivePath)
	} else {
		file, err = Backend.NewFileReadSeeker(fileDetails.ArchivePath)
	}

	if err != nil {
		log.Errorf("could not find archive file %s, %s", fileDetails.ArchivePath, err)
		c.String(http.StatusInternalServerError, "archive error")

		return
	}

	c.Header("Content-Type", "application/octet-stream")
	lastModified, err := time.Parse(time.RFC3339, fileDetails.LastModified)
	if err != nil {
		log.Errorf("failed to parse last modified time: %v", err)
		c.AbortWithStatus(http.StatusInternalServerError)

		return
	}

	c.Header("Content-Disposition", fmt.Sprintf("attachment; filename=%v", fileID))
	c.Header("ETag", fileDetails.DecryptedChecksum)
	c.Header("Last-Modified", lastModified.Format(http.TimeFormat))

	if c.GetBool("S3") {

		// set the user and server public keys that is send from htsget
		log.Debugf("Got to setting the headers: %s", c.GetHeader("client-public-key"))
		c.Header("Client-Public-Key", c.GetHeader("Client-Public-Key"))
	}

	if c.Request.Method == http.MethodHead {

		c.Header("Accept-Ranges", "bytes")

		// Header size can vary if doing parts so we add a dataeditlist packet,
		// but ignore that here.

		c.Header("Server-Additional-Bytes", fmt.Sprint(len(fileDetails.Header)))
		c.Header("Client-Additional-Bytes", fmt.Sprint(len(fileDetails.Header)))

		if c.Param("type") == "encrypted" {
			// Update the content length to match the encrypted file size
			c.Header("Content-Length", fmt.Sprint(len(fileDetails.Header)+fileDetails.ArchiveSize))
		} else {
			c.Header("Content-Length", fmt.Sprint(len(fileDetails.Header)+fileDetails.DecryptedSize))
		}

		return
	}

	// Prepare the file for streaming, encrypted or decrypted

	var fileStream io.Reader

	if c.Param("type") == "encrypted" {
		// Manage case of encrypted file
		downloadEncrypted(c, fileDetails, coords, file)

		return
	}

	// Reencrypt header for use with our temporary key
	newHeader, err := reencryptHeader(fileDetails.Header, config.Config.App.Crypt4GHPublicKeyB64)
	if err != nil {
		log.Errorf("Failed to reencrypt the file header, reason: %v", err)
		c.String(http.StatusInternalServerError, "file re-encryption error")

		return
	}

	newHr := bytes.NewReader(newHeader)

	if len(coords) == 0 {
		fileStream = io.MultiReader(newHr, file)
	} else {
		seeker, _ := file.(io.ReadSeeker)
		fileStream, err = storage.SeekableMultiReader(newHr, seeker)
		if err != nil {
			log.Errorf("Failed to construct SeekableMultiReader, reason: %v", err)
			c.String(http.StatusInternalServerError, "file decoding error")

			return
		}
	}

	c4ghfileStream, err := streaming.NewCrypt4GHReader(fileStream, config.Config.App.Crypt4GHPrivateKey, nil)
	if err != nil {
		log.Errorf("could not prepare file for streaming, %s", err)
		c.String(http.StatusInternalServerError, "file stream error")

		return
	}
	defer c4ghfileStream.Close()

	if len(coords) == 0 {
		// No coordinates specified, so we're sending the whole file
		_, err = io.Copy(c.Writer, c4ghfileStream)

		if err != nil {
			log.Errorf("Error while sending stream: %v", err)
			// Probably to late for errors but we'll try
			c.String(http.StatusInternalServerError, "an error occurred while sending stream")
		}

		return
	}

	// Coordinates specified, so we'll send only the requested range
	// Should we send as parts if more than one range?

	// If coordinates given, check if we're not sending from start
	err = seekToStartPos(c4ghfileStream, coords[0].start)
	if err != nil {
		log.Errorf("Could not seek stream: %v", err)
		c.String(http.StatusInternalServerError, "file decoding error")

		return
	}

	fileStream = c4ghfileStream

	// Coordinates specified, so we'll send only the requested range
	// Seek to the start position

	_, err = io.CopyN(c.Writer, fileStream, coords[0].end-coords[0].start)

	if err != nil {
		log.Errorf("error occurred while sending stream: %v", err)
		c.String(http.StatusInternalServerError, "an error occurred")

		return
	}
}

func downloadEncrypted(c *gin.Context, fileDetails *database.FileDownload, coords []coordinates, file io.Reader) {
	var dataeditlist []uint64
	var err error

	if len(coords) > 0 {
		dataeditlist, err = adjustCoordinates(coords, fileDetails)

		if err != nil {
			log.Errorf("Byte range coordinates invalid! %v", err)
			c.String(http.StatusBadRequest, "Bad request range ")

			return
		}
	}

	// The key provided in the header should be base64 encoded
	reencKey := c.GetHeader("Client-Public-Key")
	if reencKey == "" {
		c.String(http.StatusBadRequest, "c4gh public key is missing from the header")

		return
	}

	log.Debugf("Public key from the request header = %v", reencKey)
	log.Debugf("old c4gh file header = %v\n", fileDetails.Header)
	clientHeader, err := reencryptHeader(fileDetails.Header, reencKey, dataeditlist...)
	if err != nil {
		log.Errorf("Failed to reencrypt the file header, reason: %v", err)
		c.String(http.StatusInternalServerError, "file re-encryption error")

		return
	}

	log.Debugf("Reencrypted c4gh file header = %v", clientHeader)

	newHr := bytes.NewReader(clientHeader)

	if len(coords) == 0 {
		// No coordinates specified, so we're sending the whole file
		fileStream := io.MultiReader(newHr, file)
		_, err = io.Copy(c.Writer, fileStream)

		if err != nil {
			log.Errorf("Error while sending encrypted stream: %v", err)
			c.String(http.StatusInternalServerError, "Errow while sending file")
		}

		return
	}

	// We have at least one range specified

	// We start by sending the header (reencrypted for the key passed from the client)
	copied, err := io.Copy(c.Writer, newHr)
	if err != nil || copied != int64(len(clientHeader)) {
		log.Errorf("Error (%v) or unexpected length copied of header (%v instead of %v) ", err, copied, len(clientHeader))
		c.String(http.StatusInternalServerError, "file error")

		return

	}

	seeker, ok := file.(io.ReadSeeker)
	if !ok {
		log.Errorf("Failed to make ReadSeeker of archive source")
		c.String(http.StatusInternalServerError, "file error")

		return
	}

	err = seekToStartPos(seeker, coords[0].start)

	if err != nil {
		log.Errorf("Could not seek stream: %v", err)
		c.String(http.StatusInternalServerError, "file decoding error")

		return
	}

	_, err = io.CopyN(c.Writer, seeker, coords[0].end-coords[0].start)
	if err != nil {
		log.Errorf("Error while sending partial stream: %v", err)
		c.String(http.StatusInternalServerError, "file sending error")

		return
	}
}

var seekToStartPos = func(fileStream io.ReadSeeker, start int64) error {
	if start == 0 {
		return nil
	}

	// We don't want to read from start, skip ahead to where we should be
	_, err := fileStream.Seek(start, 0)
	if err != nil {

		return fmt.Errorf("error occurred while finding sending start: %v", err)
	}

	return nil
}

// cordinates struct to hold start and end coordinates, allows recording if an entry
// was specified (as opposed to default value/derived), but this is not used now.
// coordinates are right-open intervals, so start is inclusive and end is exclusive
// (end should be the first byte not included)
type coordinates struct {
	start          int64
	end            int64
	startSpecified bool
	endSpecified   bool
}

// getCoordinates figures out if the requests specifies start and end coordinates
func getCoordinates(c *gin.Context, fileDetails *database.FileDownload) (coords []coordinates, err error) {

	// Range has higher priority than query params, so check that first
	header := c.GetHeader("Range")

	if header == "" {
		// Header not specified, so we'll check query parameters
		return getCoordinatesFromQuery(c, fileDetails)
	}

	// Header specified, so we'll parse that
	if !strings.HasPrefix(header, "bytes=") {
		err = fmt.Errorf("header Range specified (%v) but in unknown unit, expected bytes", header)

		return
	}

	ranges := strings.Split(strings.TrimPrefix(header, "bytes="), ",")

	// Loop over all ranges specified
	for _, rangeSpec := range ranges {

		rangeParts := strings.Split(rangeSpec, "-")

		//	Prefill with size from header
		coord := coordinates{end: int64(fileDetails.DecryptedSize)}

		if len(rangeParts) == 1 {
			// No dash in range
			err = fmt.Errorf("Invalid range specified (%v) in Range header %v, expected dash", rangeSpec, header)

			return
		}

		if len(rangeParts[0]) > 0 {
			// Start (left of dash) specified
			coord.startSpecified = true
			coord.start, err = strconv.ParseInt(rangeParts[0], 10, 64)
			if err != nil {
				return
			}
		}

		if len(rangeParts[1]) > 0 {
			// End (right of dash) specified
			coord.endSpecified = true
			var endValue int64
			endValue, err = strconv.ParseInt(rangeParts[1], 10, 64)
			if err != nil {
				return
			}

			if !coord.startSpecified {
				// Range specified as -suffix, meaning we want the last suffix bytes,
				// end is filled in already
				coord.start = int64(fileDetails.DecryptedSize) - endValue
			} else {
				// range intervals are closed (inclusive) whereas coordinates are right-open, so add 1 to the value from range
				coord.end = endValue + 1
			}
		}

		if coord.start > coord.end {
			err = fmt.Errorf("endCoordinate must be greater than startCoordinate")

			return
		}

		if coord.start >= int64(fileDetails.DecryptedSize) || coord.end > int64(fileDetails.DecryptedSize) {
			err = fmt.Errorf("Start (%d) or end (%d) coordinate outside file size %d", coord.start, coord.end, fileDetails.DecryptedSize)

			return
		}

		coords = append(coords, coord)
	}

	// We had a header specified, so we're done, we shouldn't parse query
	// parameters

	return
}

func getCoordinatesFromQuery(c *gin.Context, fileDetails *database.FileDownload) (coords []coordinates, err error) {
	// Get query params
	qStart, startGiven := c.GetQuery("startCoordinate")
	qEnd, endGiven := c.GetQuery("endCoordinate")

	// Neither specified, bail out
	if !startGiven && !endGiven {
		// No coordinates specified
		return
	}

	//	Prefill with size from header
	coord := coordinates{end: int64(fileDetails.DecryptedSize)}

	// Parse and verify coordinates are valid
	if startGiven {
		var startValue int64
		startValue, err = strconv.ParseInt(strings.TrimSpace(qStart), 10, 0)
		if err != nil {
			log.Errorf("failed to convert start coordinate %v to integer, %s", qStart, err)

			return
		}

		if startValue >= 0 {
			coord.start = startValue
		} else {
			// Negative start value, so we want to start from the end
			coord.start = int64(fileDetails.DecryptedSize) + startValue
		}

		coord.startSpecified = true
	}

	if endGiven {
		var endValue int64
		endValue, err = strconv.ParseInt(strings.TrimSpace(qEnd), 10, 0)
		if err != nil {
			log.Errorf("failed to convert end coordinate %v to integer, %s", qEnd, err)

			return
		}

		if endValue >= 0 {
			coord.end = endValue
		} else {
			// Negative start value, so we want to start from the end
			coord.end = int64(fileDetails.DecryptedSize) + endValue
		}

		coord.endSpecified = true
	}

	if coord.end < coord.start {
		log.Errorf("endCoordinate=%d must be greater than startCoordinate=%d", coord.end, coord.start)
		err = fmt.Errorf("endCoordinate must be greater than startCoordinate")

		return
	}

	if coord.start >= int64(fileDetails.DecryptedSize) || coord.end > int64(fileDetails.DecryptedSize) {
		log.Errorf("Start (%d) or end (%d) coordinate outside file ", coord.start, coord.end)
		err = fmt.Errorf("start or end coordinate outside file size")

		return
	}

	coords = append(coords, coord)

	return
}

// Calculates the start and end coordinates to use for encrypted transfer.
// This includes transforming the coordinates from the virtual decrypted stream
// to the in file encrypted stream (which includes MACs and other overheads)
// returns a dataeditlist and any possible error
var adjustCoordinates = func(coords []coordinates, fileDetails *database.FileDownload) (del []uint64, err error) {

	if len(coords) == 0 {
		// No coordinates specified so send the whole file, nothing to do
		return
	}

	totalWant := coords[0].end - coords[0].start
	var alignedStart, alignedEnd int64

	if coords[0].start > 0 {
		// Align to 64k boundary
		alignedStart = coords[0].start - (coords[0].start % 65536)

		if coords[0].start != alignedStart {
			del = append(del, uint64(coords[0].start-alignedStart))
		}

		coords[0].start = alignedStart / 65536 * 65564
	}

	// Align end to 64k boundary, adjusting for padding
	if coords[0].end%65536 == 0 {
		alignedEnd = coords[0].end
	} else {
		alignedEnd = coords[0].end - (coords[0].end % 65536) + 65536
	}

	if coords[0].end != int64(fileDetails.DecryptedSize) {
		// If we don't want to grab the rest of the file, adjust data edit list

		if len(del) == 0 {
			// No initial skip added, so record that we're grabbing data from the start
			// this is zero since the case of not reading from start added one above
			del = append(del, 0)
		}

		del = append(del, uint64(totalWant))
	}

	coords[0].end = alignedEnd / 65536 * 65564

	// If the end coordinate is beyond the file size, adjust it
	if coords[0].end > int64(fileDetails.ArchiveSize) {
		coords[0].end = int64(fileDetails.ArchiveSize)
	}

	return
}
